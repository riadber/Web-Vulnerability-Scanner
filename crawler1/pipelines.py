# crawler/sqlite_pipeline.py

import sqlite3

class SQLitePipeline(object):
    def open_spider(self, spider):
        self.connection = sqlite3.connect('urls.db')
        self.cursor = self.connection.cursor()
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS urls (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                url TEXT NOT NULL,
                status_code INTEGER NOT NULL
            )
        ''')

    def close_spider(self, spider):
        self.connection.commit()
        self.connection.close()

    def process_item(self, item, spider):
        existing_url = self.cursor.execute('SELECT * FROM urls WHERE url = ?', (item['url'],)).fetchone()

        if existing_url:
            
            spider.logger.info(f"URL '{item['url']}' already exists in the database. Skipping insertion.")
        else:
            
            self.cursor.execute('INSERT INTO urls (url, status_code) VALUES (?, ?)', (item['url'], item['status_code']))
            spider.logger.info(f"Inserted URL '{item['url']}' with status code {item['status_code']} into the database.")

        return item